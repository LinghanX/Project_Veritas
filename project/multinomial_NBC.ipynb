{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Transformed text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title</td>\n",
       "      <td>text</td>\n",
       "      <td>label\\r</td>\n",
       "      <td>[text]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE\\r</td>\n",
       "      <td>[daniel, greenfield, shillman, journal, fellow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE\\r</td>\n",
       "      <td>[googl, pinterest, digg, linkedin, reddit, stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL\\r</td>\n",
       "      <td>[u, secretari, state, john, f, kerri, said, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE\\r</td>\n",
       "      <td>[kayde, king, kaydeek, novemb, 9, 2016, lesson...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL\\r</td>\n",
       "      <td>[primari, day, new, york, front, runner, hilla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>I’m not an immigrant, but my grandparents are....</td>\n",
       "      <td>FAKE\\r</td>\n",
       "      <td>[immigr, grandpar, 50, year, ago, arriv, new, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>FAKE\\r</td>\n",
       "      <td>[share, bayle, luciani, left, screenshot, bayl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106</td>\n",
       "      <td>A Czech stockbroker who saved more than 650 Je...</td>\n",
       "      <td>REAL\\r</td>\n",
       "      <td>[czech, stockbrok, save, 650, jewish, children...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>Hillary Clinton and Donald Trump made some ina...</td>\n",
       "      <td>REAL\\r</td>\n",
       "      <td>[hillari, clinton, donald, trump, made, inaccu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>Iranian negotiators reportedly have made a las...</td>\n",
       "      <td>REAL\\r</td>\n",
       "      <td>[iranian, negoti, report, made, last, ditch, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>With all three Clintons in Iowa, a glimpse at ...</td>\n",
       "      <td>CEDAR RAPIDS, Iowa — “I had one of the most wo...</td>\n",
       "      <td>REAL\\r</td>\n",
       "      <td>[cedar, rapid, iowa, one, wonder, ralli, entir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Donald Trump’s Shockingly Weak Delegate Game S...</td>\n",
       "      <td>Donald Trump’s organizational problems have go...</td>\n",
       "      <td>REAL\\r</td>\n",
       "      <td>[donald, trump, organiz, problem, gone, bad, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Strong Solar Storm, Tech Risks Today | S0 News...</td>\n",
       "      <td>Click Here To Learn More About Alexandra's Per...</td>\n",
       "      <td>FAKE\\r</td>\n",
       "      <td>[click, learn, alexandra, person, essenc, psyc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10 Ways America Is Preparing for World War 3</td>\n",
       "      <td>October 31, 2016 at 4:52 am\\nPretty factual ex...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>[octob, 31, 2016, 4, 52, pretti, factual, exce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                                               title   \n",
       "1                        You Can Smell Hillary’s Fear   \n",
       "2   Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "3         Kerry to go to Paris in gesture of sympathy   \n",
       "4   Bernie supporters on Twitter erupt in anger ag...   \n",
       "5    The Battle of New York: Why This Primary Matters   \n",
       "6                                         Tehran, USA   \n",
       "7   Girl Horrified At What She Watches Boyfriend D...   \n",
       "8                   ‘Britain’s Schindler’ Dies at 106   \n",
       "9   Fact check: Trump and Clinton at the 'commande...   \n",
       "10  Iran reportedly makes new push for uranium con...   \n",
       "11  With all three Clintons in Iowa, a glimpse at ...   \n",
       "12  Donald Trump’s Shockingly Weak Delegate Game S...   \n",
       "13  Strong Solar Storm, Tech Risks Today | S0 News...   \n",
       "14       10 Ways America Is Preparing for World War 3   \n",
       "\n",
       "                                                 text    label  \\\n",
       "0                                                text  label\\r   \n",
       "1   Daniel Greenfield, a Shillman Journalism Fello...   FAKE\\r   \n",
       "2   Google Pinterest Digg Linkedin Reddit Stumbleu...   FAKE\\r   \n",
       "3   U.S. Secretary of State John F. Kerry said Mon...   REAL\\r   \n",
       "4   — Kaydee King (@KaydeeKing) November 9, 2016 T...   FAKE\\r   \n",
       "5   It's primary day in New York and front-runners...   REAL\\r   \n",
       "6   I’m not an immigrant, but my grandparents are....   FAKE\\r   \n",
       "7   Share This Baylee Luciani (left), Screenshot o...   FAKE\\r   \n",
       "8   A Czech stockbroker who saved more than 650 Je...   REAL\\r   \n",
       "9   Hillary Clinton and Donald Trump made some ina...   REAL\\r   \n",
       "10  Iranian negotiators reportedly have made a las...   REAL\\r   \n",
       "11  CEDAR RAPIDS, Iowa — “I had one of the most wo...   REAL\\r   \n",
       "12  Donald Trump’s organizational problems have go...   REAL\\r   \n",
       "13  Click Here To Learn More About Alexandra's Per...   FAKE\\r   \n",
       "14  October 31, 2016 at 4:52 am\\nPretty factual ex...     FAKE   \n",
       "\n",
       "                                     Transformed text  \n",
       "0                                              [text]  \n",
       "1   [daniel, greenfield, shillman, journal, fellow...  \n",
       "2   [googl, pinterest, digg, linkedin, reddit, stu...  \n",
       "3   [u, secretari, state, john, f, kerri, said, mo...  \n",
       "4   [kayde, king, kaydeek, novemb, 9, 2016, lesson...  \n",
       "5   [primari, day, new, york, front, runner, hilla...  \n",
       "6   [immigr, grandpar, 50, year, ago, arriv, new, ...  \n",
       "7   [share, bayle, luciani, left, screenshot, bayl...  \n",
       "8   [czech, stockbrok, save, 650, jewish, children...  \n",
       "9   [hillari, clinton, donald, trump, made, inaccu...  \n",
       "10  [iranian, negoti, report, made, last, ditch, p...  \n",
       "11  [cedar, rapid, iowa, one, wonder, ralli, entir...  \n",
       "12  [donald, trump, organiz, problem, gone, bad, w...  \n",
       "13  [click, learn, alexandra, person, essenc, psyc...  \n",
       "14  [octob, 31, 2016, 4, 52, pretti, factual, exce...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|VOCABULARY| 2038\n",
      "|W(REAL)| 2862\n",
      "|W(FAKE)| 2823\n",
      "|P(REAL)| 0.5\n",
      "|P(FAKE)| 0.5\n",
      "SMOOTHNING FACTOR (S) 1\n",
      "Predicting the class for new Sample now\n",
      "Probability of word|fake 3.29520796116474e-192\n",
      "Probability of word|real 3.4327009162850705e-197\n",
      "FAKE\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import scipy.io\n",
    "import nltk.data\n",
    "import nltk.tokenize\n",
    "import nltk.stem\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "SMOOTHNING_FACTOR = 1\n",
    "world_label_matrix = []\n",
    "NUM_OF_LABELS = 2\n",
    "\n",
    "label_index = {\n",
    "    \"FAKE\": 0,\n",
    "    \"REAL\": 1\n",
    "}\n",
    "\n",
    "def extract_words(text, stemmer = None, remove_stopwords = False):\n",
    "    \"\"\"\n",
    "    Strategy used:\n",
    "    1. Tokenize\n",
    "    2. Stemming\n",
    "    3. Stop word removal\n",
    "    \"\"\"\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    if stemmer is None:\n",
    "        words = [token.lower() for token in tokens]\n",
    "    else:\n",
    "        words = [stemmer.stem(word.lower()) for word in tokens]\n",
    "    if remove_stopwords:\n",
    "        words = [word for word in words if word not in stopwords.words('english')]\n",
    "\n",
    "    return words\n",
    "\n",
    "def build_vocabulary(documents):\n",
    "    \"\"\"\n",
    "    Creating a list of the total unique worlds found in the corpus.\n",
    "    \"\"\"\n",
    "    vocabulary = set()\n",
    "    for doc in documents:\n",
    "        vocabulary.update([word for word in doc])\n",
    "    vocabulary = list(vocabulary)\n",
    "    return vocabulary\n",
    "\n",
    "def get_word_count_by_label(documents):\n",
    "    \"\"\"\n",
    "    Returns the total number of words in each class including\n",
    "    muliple occurences of the same world\n",
    "    \"\"\"\n",
    "    label_word_count = {\n",
    "        \"FAKE\": 0,\n",
    "        \"REAL\": 0\n",
    "    }\n",
    "    for index, row in documents.iterrows():\n",
    "        # to skip the first line which is of not importance to us\n",
    "        if row[\"label\"].strip().upper() == \"LABEL\":\n",
    "            continue\n",
    "        else:\n",
    "            label_word_count[row[\"label\"].strip().upper()] += len(row[\"Transformed text\"])\n",
    "    return label_word_count\n",
    "\n",
    "def calculate_prior_probabilities(documents):\n",
    "    \"\"\"\n",
    "    Returns the Prior probabilies of FAKE/REAL classes from the corpus\n",
    "    \"\"\"\n",
    "    label_priors = {\n",
    "        \"FAKE\": 0,\n",
    "        \"REAL\": 0\n",
    "    }\n",
    "    for index, row in documents.iterrows():\n",
    "        # to skip the first line which is of not importance to us\n",
    "        if row[\"label\"].strip().upper() == \"LABEL\":\n",
    "            continue\n",
    "        else:\n",
    "            label_priors[row[\"label\"].strip().upper()] += 1\n",
    "    return label_priors\n",
    "\n",
    "def init_label_word_count_matrix(num_of_words):\n",
    "    matrix = []\n",
    "    for i in range(num_of_words):\n",
    "        matrix.append([0 for n in range(NUM_OF_LABELS)])\n",
    "    return matrix\n",
    "\n",
    "def label_word_count_matrix(vocabulary, documents):\n",
    "    num_of_words = len(vocabulary)\n",
    "    matrix = init_label_word_count_matrix(num_of_words)\n",
    "    for row_index in range(num_of_words):\n",
    "        for index, row in documents.iterrows():\n",
    "            cleaned_label = row[\"label\"].strip().upper()\n",
    "            if cleaned_label == \"LABEL\":\n",
    "                continue\n",
    "            col_index = label_index[cleaned_label]\n",
    "            matrix[row_index][col_index] += row[\"Transformed text\"].count(vocabulary[row_index])\n",
    "    return matrix\n",
    "\n",
    "def prob_of_wrd_gvn_class(vocabulary, fake_word_count, real_word_count, label_word_matrix, word):\n",
    "    \"\"\"\n",
    "    Computes the probabilities for the given text for given class\n",
    "    \"\"\"\n",
    "    num_of_words = len(vocabulary)\n",
    "    try:\n",
    "        word_index = vocabulary.index(word)\n",
    "        word_frequency_in_fake_class = label_word_matrix[word_index][label_index[\"FAKE\"]]\n",
    "        word_frequency_in_real_class = label_word_matrix[word_index][label_index[\"REAL\"]]\n",
    "    except ValueError as err:\n",
    "        # word is not present in the vocabulary contructed\n",
    "        word_frequency_in_fake_class = word_frequency_in_real_class = 0\n",
    "    prob_of_wrd_gvn_fake = float(\n",
    "        word_frequency_in_fake_class + SMOOTHNING_FACTOR)/float(\n",
    "        fake_word_count + num_of_words)\n",
    "    prob_of_wrd_gvn_real = float(\n",
    "        word_frequency_in_real_class + SMOOTHNING_FACTOR)/float(\n",
    "        real_word_count + num_of_words)\n",
    "    return prob_of_wrd_gvn_fake, prob_of_wrd_gvn_real\n",
    "\n",
    "\n",
    "def multinomial_NBC(\n",
    "    new_sample, vocabulary, fake_wrd_cnt, real_wrd_cnt, label_wrd_matrix, prior_of_fake, prior_of_real):\n",
    "    words = extract_words(new_sample)\n",
    "    product_gvn_fake = prior_of_fake\n",
    "    product_gvn_real = prior_of_real\n",
    "    for word in words:\n",
    "        prob_of_wrd_gvn_fake, prob_of_wrd_gvn_real = prob_of_wrd_gvn_class(\n",
    "                vocabulary,\n",
    "                fake_wrd_cnt,\n",
    "                real_wrd_cnt,\n",
    "                label_wrd_matrix, word)\n",
    "        product_gvn_fake*=prob_of_wrd_gvn_fake\n",
    "        product_gvn_real*=prob_of_wrd_gvn_real\n",
    "    \n",
    "    print(\"Probability of word|fake\", product_gvn_fake)\n",
    "    print(\"Probability of word|real\", product_gvn_real)\n",
    "    if product_gvn_fake > product_gvn_real:\n",
    "        return \"FAKE\"\n",
    "    else:\n",
    "        return \"REAL\"\n",
    "    \n",
    "def main():\n",
    "    try:\n",
    "        dataDF = pd.read_csv(\n",
    "            \"../data/small_dataset.csv\",\n",
    "            sep=',', lineterminator='\\n',\n",
    "            names = [\"title\", \"text\", \"label\"], encoding=\"utf-8\")\n",
    "        snowball = nltk.stem.snowball.EnglishStemmer()\n",
    "        dataDF[\"Transformed text\"] = dataDF.apply(\n",
    "            lambda row: extract_words(row['text'], snowball, True), axis=1)\n",
    "        display(dataDF)\n",
    "        # Vocabulary building happens with the transformed text\n",
    "        vocabulary = build_vocabulary(dataDF[\"Transformed text\"])\n",
    "        num_of_wrds = len(vocabulary)\n",
    "        print(\"|VOCABULARY|\", num_of_wrds)\n",
    "        label_word_count = get_word_count_by_label(dataDF)\n",
    "        label_priors = calculate_prior_probabilities(dataDF)\n",
    "        matrix = label_word_count_matrix(vocabulary, dataDF)\n",
    "        prior_of_real = float(label_priors[\"REAL\"])/float(label_priors[\"REAL\"] + label_priors[\"FAKE\"])\n",
    "        prior_of_fake = float(label_priors[\"FAKE\"])/float(label_priors[\"REAL\"] + label_priors[\"FAKE\"])\n",
    "        real_wrd_cnt = label_word_count[\"REAL\"]\n",
    "        fake_wrd_cnt = label_word_count[\"FAKE\"]\n",
    "        print(\"|W(REAL)|\", real_wrd_cnt)\n",
    "        print(\"|W(FAKE)|\", fake_wrd_cnt)\n",
    "        print(\"|P(REAL)|\", prior_of_real)\n",
    "        print(\"|P(FAKE)|\", prior_of_fake)\n",
    "        print(\"SMOOTHNING FACTOR (S)\", SMOOTHNING_FACTOR)\n",
    "#         display(matrix)\n",
    "        print(\"Predicting the class for new Sample now\")\n",
    "        new_sample = \"October 31, 2016 at 4:52 am Pretty factual except for women in the selective service. American military is still voluntary only and hasn't been a draft since Vietnam war. The comment was made by a 4 star general of the army about drafting women and he said it to shut up liberal yahoos.\"\n",
    "        print(multinomial_NBC(\n",
    "            new_sample, vocabulary, fake_wrd_cnt, real_wrd_cnt, matrix, prior_of_fake, prior_of_real))\n",
    "    except IOError as err:\n",
    "        print(str(err))\n",
    "    except UnicodeDecodeError as err:\n",
    "        print(str(err))\n",
    "    except Exception as err:\n",
    "        print(str(err))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
